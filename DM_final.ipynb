{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data loading and data preprocessing\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "#Note spam =1 ham =0 \n",
    "data1 = pd.read_excel('spamham/SPAM text message 20170820 - Data1.xlsx')\n",
    "\n",
    "x=[]\n",
    "y=[]\n",
    "for key,row1 in data1.iterrows():\n",
    "\n",
    "    val=0\n",
    "    #string=str(row1['Message'])\n",
    "    string=re.sub(r'[^a-z A-Z 0-9]', '', str(row1['Message']))\n",
    "    #print(string)\n",
    "    string=string.lower()\n",
    "    x.append(string)\n",
    "    if(row1['Category']=='spam'):\n",
    "        val=1\n",
    "    y.append(val)\n",
    "    \n",
    "data2 = pd.read_csv('spamham/lingSpam.csv')\n",
    "\n",
    "for key,row2 in data2.iterrows():\n",
    "    string=str(row2['Body'])\n",
    "    string=re.sub(r'[^a-z A-Z 0-9]', '', string)\n",
    "    string=string.lower()\n",
    "    x.append(string)\n",
    "    y.append(row2['Label'])\n",
    "    \n",
    "    \n",
    "data3 = pd.read_csv('spamham/completeSpamAssassin.csv')\n",
    "\n",
    "for key,row3 in data3.iterrows():\n",
    "    string=str(row3['Body'])\n",
    "    string=re.sub(r'[^a-z A-Z 0-9]', '', string)\n",
    "    string=string.lower()\n",
    "    x.append(string)\n",
    "    y.append(row3['Label'])\n",
    "    \n",
    "data4 = pd.read_csv('spamham/enronSpamSubset.csv')\n",
    "\n",
    "for key,row4 in data4.iterrows():\n",
    "    string=str(row4['Body'])\n",
    "    string=re.sub(r'[^a-z A-Z 0-9]', '', string)\n",
    "    string=string.lower()\n",
    "    x.append(string)\n",
    "    y.append(row4['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24223\n",
      "24223\n"
     ]
    }
   ],
   "source": [
    "#https://www.geeksforgeeks.org/removing-stop-words-nltk-python/\n",
    "#remove stop words\n",
    "s_w = set(stopwords.words('english'))\n",
    "i=0\n",
    "for strobj in x:\n",
    "    #taken from https://www.geeksforgeeks.org/removing-stop-words-nltk-python/\n",
    "    w_t=word_tokenize(strobj)\n",
    "    fs = [w for w in w_t if not w in s_w]\n",
    "    strobj1=\" \".join(fs)\n",
    "    #ends here\n",
    "    x[i]=strobj1\n",
    "    i=i+1\n",
    "    \n",
    "print(len(x))\n",
    "print(len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test dev ratio 60 20 20\n",
    "full_len=len(x)\n",
    "len_train=int(len(x)*0.6)\n",
    "len_dev=int(len(x)*0.2)\n",
    "\n",
    "train_x=x[0:len_train]\n",
    "dev_x=x[len_train:len_train+len_dev]\n",
    "test_x=x[len_train+len_dev:full_len]\n",
    "\n",
    "train_y=y[0:len_train]\n",
    "dev_y=y[len_train:len_train+len_dev]\n",
    "test_y=y[len_train+len_dev:full_len]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14533\n",
      "4846\n"
     ]
    }
   ],
   "source": [
    "#variables initialization and size check\n",
    "print(len(train_x))\n",
    "print(len(test_x))\n",
    "\n",
    "#all words in spam without repeatation\n",
    "spam_wd_set={}\n",
    "ham_wd_set={}\n",
    "spam_count=0\n",
    "ham_count=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build NB classifier model\n",
    "def build_model(data_x,data_y):\n",
    "    global spam_wd_set,ham_wd_set,spam_count,ham_count\n",
    "    i=0\n",
    "    for strobj in data_x:\n",
    "        w_t=word_tokenize(strobj)\n",
    "        w_t_set=set(w_t)\n",
    "        for w in w_t:\n",
    "            if data_y[i]==1:\n",
    "                if w not in spam_wd_set:\n",
    "                    spam_wd_set[w]=1\n",
    "                else:\n",
    "                    count=spam_wd_set[w]\n",
    "                    spam_wd_set[w]=count+1\n",
    "            else:\n",
    "                if w not in ham_wd_set:\n",
    "                    ham_wd_set[w]=1\n",
    "                else:\n",
    "                    count=ham_wd_set[w]\n",
    "                    ham_wd_set[w]=count+1                           \n",
    "        i+=1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spam and ham count\n",
    "for d in train_y:\n",
    "    if(d==1):\n",
    "        spam_count+=1\n",
    "    else:\n",
    "        ham_count+=1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for demo purpose\n",
    "train_x1=['started searching get job dayshe great potential talent',\n",
    "     'reckon need town eightish walk carpark']\n",
    "train_y1=[1,0]\n",
    "build_model(train_x,train_y)\n",
    "#class probability\n",
    "spam_class_prob=spam_count/len(train_x)\n",
    "ham_class_prob=ham_count/len(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7670130048854331"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ham_class_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test NB classiifier \n",
    "def test_model(data_x,data_y,alpha):\n",
    "    \n",
    "    i=0\n",
    "    correct_count=0\n",
    "    accuracy=0\n",
    "    for data in data_x:\n",
    "        w_t=word_tokenize(data)\n",
    "        spam_prob=1\n",
    "        ham_prob=1\n",
    "        final_lable=-20#random value initialized\n",
    "        for w in w_t:\n",
    "            if(w not in spam_wd_set):\n",
    "                spam_prob=spam_prob*(alpha/(spam_count+2*alpha))\n",
    "                #print(\"spam \",spam_prob)\n",
    "            else:\n",
    "                spam_prob=spam_prob*((spam_wd_set[w]+alpha)/(spam_count+2*alpha))\n",
    "            if(w not in ham_wd_set):\n",
    "                ham_prob=ham_prob*(alpha/(ham_count+2*alpha))\n",
    "                #print(\"ham \",ham_prob)\n",
    "            else:\n",
    "                ham_prob=ham_prob*((ham_wd_set[w]+alpha)/(ham_count+2*alpha))\n",
    "       \n",
    "        \n",
    "        spam_prob=spam_prob*spam_class_prob\n",
    "        ham_prob=ham_prob*ham_class_prob\n",
    "        if(spam_prob>=ham_prob):\n",
    "            final_lable=1\n",
    "        else:\n",
    "            final_lable=0\n",
    "        if(data_y[i]==final_lable):\n",
    "            correct_count=correct_count+1\n",
    "        i=i+1\n",
    "\n",
    "    accuracy=(correct_count/len(data_x))*100\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using dev dataset and aplha 0  92.36168455821635\n"
     ]
    }
   ],
   "source": [
    "acc_NB=test_model(dev_x,dev_y,0)\n",
    "print(\"Accuracy using dev dataset and aplha 0 \",acc_NB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using dev dataset and aplha 1  70.64409578860446\n"
     ]
    }
   ],
   "source": [
    "#overfiting model so giving alpha value to 1\n",
    "acc_NB=test_model(dev_x,dev_y,1)\n",
    "print(\"Accuracy using dev dataset and aplha 1 \",acc_NB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4444444444444444\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Jaccord  = number of 11 matches / number of non-zero attributes\n",
    "words_doc1 = {'data', 'is', 'the', 'new', 'oil', 'of', 'digital', 'economy'}\n",
    "words_doc2 = {'data', 'is', 'a', 'new', 'oil'}\n",
    "intersec = words_doc1.intersection(words_doc2)\n",
    "union = words_doc1.union(words_doc2)\n",
    "print(len(intersec)/len(union))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#doing this for knn and kmeans algorithm\n",
    "test_dis_x=dev_x[0:50]\n",
    "train_dis_x=train_x[0:1000]\n",
    "test_dis_y=dev_y[0:50]\n",
    "train_dis_y=train_y[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#k-nn, k=3\n",
    "def knn_model(train_data_x,train_data_y,test_data_x,test_data_y):\n",
    "    correct=0\n",
    "    accuracy=0\n",
    "    import operator\n",
    "    for strobj in test_data_x:\n",
    "        test_word_ls=set(word_tokenize(strobj))\n",
    "        dist_obj={}\n",
    "        final_label=-20\n",
    "        for tr in train_data_x:\n",
    "            train_word_ls=set(word_tokenize(tr))\n",
    "            intersec = test_word_ls.intersection(train_word_ls)\n",
    "            union = test_word_ls.union(train_word_ls)\n",
    "            if(intersec!=0):\n",
    "                dist=len(intersec)/len(union)\n",
    "            tr_x=train_data_x.index(tr)\n",
    "            dist_obj[tr_x]=1-dist\n",
    "        dict_obj=dict(sorted(dist_obj.items(), key=operator.itemgetter(1))[:3])\n",
    "        c_spam=0\n",
    "        c_ham=0\n",
    "        for key in dict_obj:\n",
    "            if(train_data_y[key]==1):\n",
    "                c_spam+=1\n",
    "            else:\n",
    "                c_ham+=1\n",
    "        if(c_spam>c_ham):\n",
    "            final_label=1\n",
    "        else:\n",
    "            final_label=0\n",
    "        index_x=test_data_x.index(strobj)\n",
    "        if(final_label==test_data_y[index_x]):\n",
    "            correct+=1\n",
    "\n",
    "    accuracy=(correct/len(test_data_x))*100\n",
    "    return accuracy   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.0\n"
     ]
    }
   ],
   "source": [
    "acc_knn=knn_model(train_dis_x,train_dis_y,test_dis_x,test_dis_y)\n",
    "print(acc_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#k-means algorithm starts here \n",
    "new_arr=[]\n",
    "i=-1\n",
    "for data in x:\n",
    "    i=i+1\n",
    "    dist=len(data)/(len(ham_wd_set)+len(spam_wd_set))\n",
    "    obj={'x':data,'y':y[i],'dist':dist,'group':-1}\n",
    "    new_arr.append(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'x': 'go jurong point crazy available bugis n great world la e buffet cine got amore wat', 'y': 0, 'dist': 0.0004298640161880498, 'group': -1}, {'x': 'free entry 2 wkly comp win fa cup final tkts 21st may 2005 text fa 87121 receive entry questionstd txt ratetcs apply 08452810075over18s', 'y': 1, 'dist': 0.0007077029534803259, 'group': -1}]\n"
     ]
    }
   ],
   "source": [
    "#k-means , here k=2 becaues wants to divide into 2 groups spam and ham\n",
    "centers=[]\n",
    "centers.append(new_arr[0])\n",
    "centers.append(new_arr[2])\n",
    "c1_wd_set=set(word_tokenize(centers[0]['x']))\n",
    "c2_wd_set=set(word_tokenize(centers[1]['x']))\n",
    "print(centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "index=-1\n",
    "for data in new_arr:\n",
    "        index+=1\n",
    "        small=100#randomly 100\n",
    "\n",
    "        x_wd_set=set(word_tokenize(data['x']))\n",
    "   \n",
    "        intersec1 = x_wd_set.intersection(c1_wd_set)\n",
    "        union1 = x_wd_set.union(c1_wd_set)\n",
    "        \n",
    "        intersec2 = x_wd_set.intersection(c2_wd_set)\n",
    "        union2 = x_wd_set.union(c2_wd_set)\n",
    "        \n",
    "        dist1=len(intersec1)/len(union1)\n",
    "        dist2=len(intersec2)/len(union2)\n",
    "        \n",
    "        if(dist1>dist2):\n",
    "            new_arr[index]['group']=centers[0]['y']\n",
    "        else:\n",
    "            new_arr[index]['group']=centers[1]['y']\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.008717474600764762, 0.0071716864685213155]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "#center value cal\n",
    "a=pd.DataFrame(new_arr)\n",
    "groupby = a.groupby('group', axis=0)\n",
    "mean_dis=[]\n",
    "for index,itr in groupby.mean().iterrows():\n",
    "    \n",
    "    if(math.isclose(itr['dist'], centers[0]['dist'], rel_tol=1e-5)):\n",
    "        print(\"same\")\n",
    "    elif(math.isclose(itr['dist'], centers[1]['dist'], rel_tol=1e-5)):\n",
    "        print(\"same\")\n",
    "    else:\n",
    "        mean_dis.append(itr['dist'])\n",
    "print(mean_dis)\n",
    "for data in new_arr:\n",
    "    if(math.isclose(data['dist'], mean_dis[0], rel_tol=1e-5)):\n",
    "        centers[0]=data\n",
    "    if(math.isclose(data['dist'], mean_dis[1], rel_tol=1e-5)):\n",
    "        centers[1]=data\n",
    "centers\n",
    "c1_wd_set=set(word_tokenize(centers[0]['x']))\n",
    "c2_wd_set=set(word_tokenize(centers[1]['x']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "index=-1\n",
    "for data in new_arr:\n",
    "        index+=1\n",
    "        small=100#randomly 100\n",
    "\n",
    "        x_wd_set=set(word_tokenize(data['x']))\n",
    "   \n",
    "        intersec1 = x_wd_set.intersection(c1_wd_set)\n",
    "        union1 = x_wd_set.union(c1_wd_set)\n",
    "        \n",
    "        intersec2 = x_wd_set.intersection(c2_wd_set)\n",
    "        union2 = x_wd_set.union(c2_wd_set)\n",
    "        \n",
    "        dist1=len(intersec1)/len(union1)\n",
    "        dist2=len(intersec2)/len(union2)\n",
    "        \n",
    "        if(dist1>dist2):\n",
    "            new_arr[index]['group']=centers[0]['y']\n",
    "        else:\n",
    "            new_arr[index]['group']=centers[1]['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.008717474600764762, 0.0071716864685213155]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "#center value cal\n",
    "a=pd.DataFrame(new_arr)\n",
    "groupby = a.groupby('group', axis=0)\n",
    "mean_dis=[]\n",
    "for index,itr in groupby.mean().iterrows():\n",
    "    \n",
    "    if(math.isclose(itr['dist'], centers[0]['dist'], rel_tol=1e-5)):\n",
    "        print(\"\")\n",
    "    elif(math.isclose(itr['dist'], centers[1]['dist'], rel_tol=1e-5)):\n",
    "        print(\"\")\n",
    "    else:\n",
    "        mean_dis.append(itr['dist'])\n",
    "print(mean_dis)\n",
    "for data in new_arr:\n",
    "    if(math.isclose(data['dist'], mean_dis[0], rel_tol=1e-5)):\n",
    "        centers[0]=data\n",
    "    if(math.isclose(data['dist'], mean_dis[1], rel_tol=1e-5)):\n",
    "        centers[1]=data\n",
    "centers\n",
    "c1_wd_set=set(word_tokenize(centers[0]['x']))\n",
    "c2_wd_set=set(word_tokenize(centers[1]['x']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.236717169632165\n"
     ]
    }
   ],
   "source": [
    "correct=0\n",
    "acc_kmeans=0\n",
    "for data in new_arr:\n",
    "    if(data['group']==data['y']):\n",
    "        correct+=1\n",
    "acc_kmeans=(correct*100)/len(new_arr)\n",
    "print(acc_kmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "langs = ['NB', 'K-NN', 'K-means']\n",
    "students = [acc_NB,acc_knn,acc_kmeans]\n",
    "ax.bar(langs,students)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using dev dataset and aplha 0  6.170037144036319\n"
     ]
    }
   ],
   "source": [
    "acc_NB=test_model(test_x,test_y,0)\n",
    "print(\"Accuracy using dev dataset and aplha 0 \",acc_NB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using dev dataset and aplha 1  72.41023524556334\n"
     ]
    }
   ],
   "source": [
    "acc_NB=test_model(test_x,test_y,1)\n",
    "print(\"Accuracy using dev dataset and aplha 1 \",acc_NB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using dev dataset and aplha 1  72.34832851836566\n"
     ]
    }
   ],
   "source": [
    "acc_NB=test_model(test_x,test_y,1/10)\n",
    "print(\"Accuracy using dev dataset and aplha 1 \",acc_NB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "congrats winner 1000 amount\n"
     ]
    }
   ],
   "source": [
    "data=\"Congrats!! You are winner of 1000 amount.\"\n",
    "data=re.sub(r'[^a-z A-Z 0-9]', '', data)\n",
    "data=data.lower()\n",
    "w_t=word_tokenize(data)\n",
    "fs = [w for w in w_t if not w in s_w]\n",
    "data=\" \".join(fs)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam_prob  congrats 0.0029533372711163615\n",
      "hamm  congrats 0.0008073921234412846\n",
      "spam_prob  winner 6.105540725875526e-05\n",
      "hamm  winner 0.008073921234412846\n",
      "spam_prob  1000 3.660439360167548e-06\n",
      "hamm  1000 0.023414371579797255\n",
      "spam_prob  amount 2.1729129101998736e-07\n",
      "hamm  amount 0.0555306360455728\n",
      "Final Spam prob  5.0626044959311724e-08\n",
      "Final ham prob  6.50110077670098e-09\n"
     ]
    }
   ],
   "source": [
    "w_t=word_tokenize(data)\n",
    "spam_prob=1\n",
    "ham_prob=1\n",
    "final_lable=-20#random value initialized\n",
    "for w in w_t:\n",
    "    if(w not in spam_wd_set):\n",
    "        spam_prob=spam_prob*0/(spam_count+2*0)\n",
    "    else:\n",
    "        spam_prob=spam_prob*((spam_wd_set[w]+0)/spam_count+2*0)\n",
    "        print(\"spam_prob \",w,spam_prob)\n",
    "    if(w not in ham_wd_set):\n",
    "         ham_prob=ham_prob*0/(ham_count+2*0)\n",
    "    else:\n",
    "        ham_prob=ham_prob*((ham_wd_set[w]+0)/ham_count+2*0)\n",
    "        print(\"hamm \",w,ham_wd_set[w]/ham_count)\n",
    "    \n",
    "spam_prob=spam_prob*spam_class_prob\n",
    "ham_prob=ham_prob*ham_class_prob\n",
    "print(\"Final Spam prob \",spam_prob)\n",
    "print(\"Final ham prob \",ham_prob)\n",
    "if(spam_prob>=ham_prob):\n",
    "    final_lable=1\n",
    "else:\n",
    "    final_lable=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_lable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to improve performance use email column of data\n",
    "data1 = pd.read_excel('spamham/SPAM text message 20170820 - Data1.xlsx')\n",
    "\n",
    "new_data=[]\n",
    "\n",
    "for key,row1 in data1.iterrows():\n",
    "    count=0\n",
    "    val=0\n",
    "    reply=0\n",
    "    stringmsg=re.sub(r'[^a-z A-Z 0-9]', '', str(row1['Message']))\n",
    "    stringmsg=stringmsg.lower()\n",
    "    stringemail=row1['Email']\n",
    "    if(row1['Category']=='spam'):\n",
    "        count+=1\n",
    "        val=1\n",
    "        if(count<4):\n",
    "            reply=1\n",
    "        else:\n",
    "            reply=0\n",
    "    else:\n",
    "        reply=1\n",
    "    obj={'strmsg':stringmsg,'stremail':stringemail,'category':val,'reply':reply}\n",
    "    new_data.append(obj)\n",
    "\n",
    "s_w = set(stopwords.words('english'))\n",
    "i=0\n",
    "for obj in new_data:\n",
    "    w_t=word_tokenize(obj['strmsg'])\n",
    "    fs = [w for w in w_t if not w in s_w]\n",
    "    strobj1=\" \".join(fs)\n",
    "    obj['strmsg']=strobj1\n",
    "    i=i+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#all words in spam without repeatation\n",
    "spam_wd_set1={}\n",
    "ham_wd_set1={}\n",
    "spam_domain_set1={}\n",
    "ham_domain_set1={}\n",
    "spam_count1=0\n",
    "ham_count1=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test dev ratio 80 20\n",
    "full_len=len(new_data)\n",
    "len_train=int(len(new_data)*0.8)\n",
    "\n",
    "train_data_new=new_data[0:len_train]\n",
    "test_data_new=new_data[len_train:full_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nb_classifier_improved(data):\n",
    "    global spam_wd_set1,ham_wd_set1,spam_domain_set1,ham_domain_set1\n",
    "    for strobj in data:\n",
    "        if(strobj['stremail']!=None and strobj['category']==1):\n",
    "            email=strobj['stremail']\n",
    "            if(type(email)==str):\n",
    "                dom=email[email.index('@') + 1 :email.index('.')]\n",
    "                if(dom not in spam_domain_set1):\n",
    "                    spam_domain_set1[dom]=1\n",
    "                else:\n",
    "                    countdom=spam_domain_set1[dom]\n",
    "                    spam_domain_set1[dom]=countdom+1\n",
    "        elif(strobj['stremail']!=None and strobj['category']==0):\n",
    "            email=strobj['stremail']\n",
    "            if(type(email)==str):        \n",
    "                dom=email[email.index('@') + 1 :email.index('.')]\n",
    "                if(dom not in ham_domain_set1):\n",
    "                    ham_domain_set1[dom]=1\n",
    "                else:\n",
    "                    countdom=ham_domain_set1[dom]\n",
    "                    ham_domain_set1[dom]=countdom+1\n",
    "            \n",
    "        w_t=word_tokenize(strobj['strmsg'])\n",
    "        w_t_set=set(w_t)\n",
    "        for w in w_t:\n",
    "            if strobj['category']==1:\n",
    "                if w not in spam_wd_set1:\n",
    "                    spam_wd_set1[w]=1\n",
    "                else:\n",
    "                    count=spam_wd_set1[w]\n",
    "                    spam_wd_set1[w]=count+1\n",
    "            else:\n",
    "                if w not in ham_wd_set1:\n",
    "                    ham_wd_set1[w]=1\n",
    "                else:\n",
    "                    count=ham_wd_set1[w]\n",
    "                    ham_wd_set1[w]=count+1                           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'strmsg': 'go jurong point crazy available bugis n great world la e buffet cine got amore wat',\n",
       " 'stremail': 'abc@test.com',\n",
       " 'category': 0,\n",
       " 'reply': 1}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classifier_improved(train_data_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in train_data_new:\n",
    "    if(d['category']==1):\n",
    "        spam_count1+=1\n",
    "    else:\n",
    "        ham_count1+=1\n",
    "        \n",
    "spam_class_prob1=spam_count1/len(train_data_new)\n",
    "ham_class_prob1=ham_count1/len(train_data_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model1(data_new,alpha):\n",
    "    \n",
    "    i=0\n",
    "    correct_count=0\n",
    "    accuracy=0\n",
    "    for data in data_new:\n",
    "        dom_prob_spam=1\n",
    "        dom_prob_ham=1\n",
    "        if(data['stremail']!=None and data['category']==1):\n",
    "            email=data['stremail']\n",
    "            if(type(email)==str):\n",
    "                dom=email[email.index('@') + 1 :email.index('.')]\n",
    "                if(dom in spam_domain_set1):\n",
    "                    count=spam_domain_set1[dom]\n",
    "                    dom_prob_spam=count/spam_count1\n",
    "                if(dom in ham_domain_set1):\n",
    "                    count=ham_domain_set1[dom]\n",
    "                    dom_prob_ham=count/ham_count1                \n",
    "        w_t=word_tokenize(data['strmsg'])\n",
    "        spam_prob=1\n",
    "        ham_prob=1\n",
    "        final_lable=-20#random value initialized\n",
    "        for w in w_t:\n",
    "            if(w not in spam_wd_set1):\n",
    "                spam_prob=spam_prob*(alpha/(spam_count1+2*alpha))*dom_prob_spam\n",
    "                #print(\"spam \",spam_prob)\n",
    "            else:\n",
    "                spam_prob=spam_prob*((spam_wd_set1[w]+alpha)/(spam_count1+2*alpha))*dom_prob_spam\n",
    "            if(w not in ham_wd_set1):\n",
    "                ham_prob=ham_prob*(alpha/(ham_count1+2*alpha))*dom_prob_ham\n",
    "                #print(\"ham \",ham_prob)\n",
    "            else:\n",
    "                ham_prob=ham_prob*((ham_wd_set1[w]+alpha)/(ham_count1+2*alpha))*dom_prob_ham\n",
    "       \n",
    "        \n",
    "        spam_prob=spam_prob*spam_class_prob1\n",
    "        ham_prob=ham_prob*ham_class_prob1\n",
    "        if(spam_prob>=ham_prob):\n",
    "            final_lable=1\n",
    "        else:\n",
    "            final_lable=0\n",
    "        if(data['category']==final_lable):\n",
    "            correct_count=correct_count+1\n",
    "        i=i+1\n",
    "\n",
    "    accuracy=(correct_count/len(data_new))*100\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60.17937219730942"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model1(test_data_new,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model2(data_new,alpha):\n",
    "    \n",
    "    i=0\n",
    "    correct_count=0\n",
    "    accuracy=0\n",
    "    for data in data_new:\n",
    "        dom_prob_spam=1\n",
    "        dom_prob_ham=1\n",
    "        if(data['stremail']!=None and data['category']==1):\n",
    "            email=data['stremail']\n",
    "            if(type(email)==str):\n",
    "                dom=email[email.index('@') + 1 :email.index('.')]\n",
    "                if(dom in spam_domain_set1):\n",
    "                    count=spam_domain_set1[dom]\n",
    "                    dom_prob_spam=count/spam_count1\n",
    "                if(dom in ham_domain_set1):\n",
    "                    count=ham_domain_set1[dom]\n",
    "                    dom_prob_ham=count/ham_count1                \n",
    "        w_t=word_tokenize(data['strmsg'])\n",
    "        spam_prob=1\n",
    "        ham_prob=1\n",
    "        final_lable=-20#random value initialized\n",
    "        for w in w_t:\n",
    "            if(w not in spam_wd_set1):\n",
    "                spam_prob=spam_prob*(alpha/(spam_count1+2*alpha))*dom_prob_spam\n",
    "                #print(\"spam \",spam_prob)\n",
    "            else:\n",
    "                spam_prob=spam_prob*((spam_wd_set1[w]+alpha)/(spam_count1+2*alpha))*dom_prob_spam\n",
    "            if(w not in ham_wd_set1):\n",
    "                ham_prob=ham_prob*(alpha/(ham_count1+2*alpha))*dom_prob_ham\n",
    "                #print(\"ham \",ham_prob)\n",
    "            else:\n",
    "                ham_prob=ham_prob*((ham_wd_set1[w]+alpha)/(ham_count1+2*alpha))*dom_prob_ham\n",
    "       \n",
    "        \n",
    "        spam_prob=spam_prob*spam_class_prob1\n",
    "        ham_prob=ham_prob*ham_class_prob1\n",
    "        if(spam_prob>ham_prob and data['reply']==0):\n",
    "            final_lable=1\n",
    "        else:\n",
    "            final_lable=0\n",
    "        if(data['category']==final_lable):\n",
    "            correct_count=correct_count+1\n",
    "        i=i+1\n",
    "\n",
    "    accuracy=(correct_count/len(data_new))*100\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60.17937219730942"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model1(test_data_new,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
