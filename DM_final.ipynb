{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "#Note spam =1 ham =0 \n",
    "data1 = pd.read_excel('spamham/SPAM text message 20170820 - Data1.xlsx')\n",
    "\n",
    "x=[]\n",
    "y=[]\n",
    "for key,row1 in data1.iterrows():\n",
    "\n",
    "    val=0\n",
    "    #string=str(row1['Message'])\n",
    "    string=re.sub(r'[^a-z A-Z 0-9]', '', str(row1['Message']))\n",
    "    #print(string)\n",
    "    string=string.lower()\n",
    "    x.append(string)\n",
    "    if(row1['Category']=='spam'):\n",
    "        val=1\n",
    "    y.append(val)\n",
    "    \n",
    "data2 = pd.read_csv('spamham/lingSpam.csv')\n",
    "\n",
    "for key,row2 in data2.iterrows():\n",
    "    string=str(row2['Body'])\n",
    "    string=re.sub(r'[^a-z A-Z 0-9]', '', string)\n",
    "    string=string.lower()\n",
    "    x.append(string)\n",
    "    y.append(row2['Label'])\n",
    "    \n",
    "    \n",
    "data3 = pd.read_csv('spamham/completeSpamAssassin.csv')\n",
    "\n",
    "for key,row3 in data3.iterrows():\n",
    "    string=str(row3['Body'])\n",
    "    string=re.sub(r'[^a-z A-Z 0-9]', '', string)\n",
    "    string=string.lower()\n",
    "    x.append(string)\n",
    "    y.append(row3['Label'])\n",
    "    \n",
    "data4 = pd.read_csv('spamham/enronSpamSubset.csv')\n",
    "\n",
    "for key,row4 in data4.iterrows():\n",
    "    string=str(row4['Body'])\n",
    "    string=re.sub(r'[^a-z A-Z 0-9]', '', string)\n",
    "    string=string.lower()\n",
    "    x.append(string)\n",
    "    y.append(row4['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24223\n",
      "24223\n"
     ]
    }
   ],
   "source": [
    "#https://www.geeksforgeeks.org/removing-stop-words-nltk-python/\n",
    "s_w = set(stopwords.words('english'))\n",
    "i=0\n",
    "for strobj in x:\n",
    "    w_t=word_tokenize(strobj)\n",
    "    fs = [w for w in w_t if not w in s_w]\n",
    "    strobj1=\" \".join(fs)\n",
    "    x[i]=strobj1\n",
    "    i=i+1\n",
    "    \n",
    "print(len(x))\n",
    "print(len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test dev ratio 60 20 20\n",
    "full_len=len(x)\n",
    "len_train=int(len(x)*0.6)\n",
    "len_dev=int(len(x)*0.2)\n",
    "\n",
    "train_x=x[0:len_train]\n",
    "dev_x=x[len_train:len_train+len_dev]\n",
    "test_x=x[len_train+len_dev:full_len]\n",
    "\n",
    "train_y=y[0:len_train]\n",
    "dev_y=y[len_train:len_train+len_dev]\n",
    "test_y=y[len_train+len_dev:full_len]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14533\n",
      "4846\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(len(train_x))\n",
    "print(len(test_x))\n",
    "\n",
    "#all words in spam without repeatation\n",
    "spam_wd_set={}\n",
    "ham_wd_set={}\n",
    "spam_count=0\n",
    "ham_count=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(data_x,data_y):\n",
    "    global spam_wd_set,ham_wd_set,spam_count,ham_count\n",
    "    i=0\n",
    "    for strobj in data_x:\n",
    "        w_t=word_tokenize(strobj)\n",
    "        w_t_set=set(w_t)\n",
    "        for w in w_t:\n",
    "            if data_y[i]==1:\n",
    "                if w not in spam_wd_set:\n",
    "                    spam_wd_set[w]=1\n",
    "                else:\n",
    "                    count=spam_wd_set[w]\n",
    "                    spam_wd_set[w]=count+1\n",
    "            else:\n",
    "                if w not in ham_wd_set:\n",
    "                    ham_wd_set[w]=1\n",
    "                else:\n",
    "                    count=ham_wd_set[w]\n",
    "                    ham_wd_set[w]=count+1                           \n",
    "        i+=1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in train_y:\n",
    "    if(d==1):\n",
    "        spam_count+=1\n",
    "    else:\n",
    "        ham_count+=1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for demo purpose\n",
    "train_x1=['started searching get job dayshe great potential talent',\n",
    "     'reckon need town eightish walk carpark']\n",
    "train_y1=[1,0]\n",
    "build_model(train_x,train_y)\n",
    "#class probability\n",
    "spam_class_prob=spam_count/len(train_x)\n",
    "ham_class_prob=ham_count/len(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7670130048854331"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ham_class_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(data_x,data_y,alpha):\n",
    "    \n",
    "    i=0\n",
    "    correct_count=0\n",
    "    accuracy=0\n",
    "    for data in data_x:\n",
    "        w_t=word_tokenize(data)\n",
    "        spam_prob=1\n",
    "        ham_prob=1\n",
    "        final_lable=-20#random value initialized\n",
    "        for w in w_t:\n",
    "            if(w not in spam_wd_set):\n",
    "                spam_prob=spam_prob*(alpha/(spam_count+2*alpha))\n",
    "                #print(\"spam \",spam_prob)\n",
    "            else:\n",
    "                spam_prob=spam_prob*((spam_wd_set[w]+alpha)/(spam_count+2*alpha))\n",
    "            if(w not in ham_wd_set):\n",
    "                ham_prob=ham_prob*(alpha/(ham_count+2*alpha))\n",
    "                #print(\"ham \",ham_prob)\n",
    "            else:\n",
    "                ham_prob=ham_prob*((ham_wd_set[w]+alpha)/(ham_count+2*alpha))\n",
    "       \n",
    "        \n",
    "        spam_prob=spam_prob*spam_class_prob\n",
    "        ham_prob=ham_prob*ham_class_prob\n",
    "        if(spam_prob>=ham_prob):\n",
    "            final_lable=1\n",
    "        else:\n",
    "            final_lable=0\n",
    "        if(data_y[i]==final_lable):\n",
    "            correct_count=correct_count+1\n",
    "        i=i+1\n",
    "\n",
    "    accuracy=(correct_count/len(data_x))*100\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using dev dataset and aplha 0  92.36168455821635\n"
     ]
    }
   ],
   "source": [
    "acc_NB=test_model(dev_x,dev_y,0)\n",
    "print(\"Accuracy using dev dataset and aplha 0 \",acc_NB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using dev dataset and aplha 1  70.64409578860446\n"
     ]
    }
   ],
   "source": [
    "#overfiting model so giving alpha value to 1\n",
    "acc_NB=test_model(dev_x,dev_y,1)\n",
    "print(\"Accuracy using dev dataset and aplha 1 \",acc_NB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4444444444444444\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Jaccord  = number of 11 matches / number of non-zero attributes\n",
    "words_doc1 = {'data', 'is', 'the', 'new', 'oil', 'of', 'digital', 'economy'}\n",
    "words_doc2 = {'data', 'is', 'a', 'new', 'oil'}\n",
    "intersec = words_doc1.intersection(words_doc2)\n",
    "union = words_doc1.union(words_doc2)\n",
    "print(len(intersec)/len(union))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#doing this for knn and kmeans algorithm\n",
    "test_dis_x=dev_x[0:50]\n",
    "train_dis_x=train_x[0:1000]\n",
    "test_dis_y=dev_y[0:50]\n",
    "train_dis_y=train_y[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#k-nn, k=3\n",
    "def knn_model(train_data_x,train_data_y,test_data_x,test_data_y):\n",
    "    correct=0\n",
    "    accuracy=0\n",
    "    import operator\n",
    "    for strobj in test_data_x:\n",
    "        test_word_ls=set(word_tokenize(strobj))\n",
    "        dist_obj={}\n",
    "        final_label=-20\n",
    "        for tr in train_data_x:\n",
    "            train_word_ls=set(word_tokenize(tr))\n",
    "            intersec = test_word_ls.intersection(train_word_ls)\n",
    "            union = test_word_ls.union(train_word_ls)\n",
    "            if(intersec!=0):\n",
    "                dist=len(intersec)/len(union)\n",
    "            tr_x=train_data_x.index(tr)\n",
    "            dist_obj[tr_x]=1-dist\n",
    "        dict_obj=dict(sorted(dist_obj.items(), key=operator.itemgetter(1))[:3])\n",
    "        c_spam=0\n",
    "        c_ham=0\n",
    "        for key in dict_obj:\n",
    "            if(train_data_y[key]==1):\n",
    "                c_spam+=1\n",
    "            else:\n",
    "                c_ham+=1\n",
    "        if(c_spam>c_ham):\n",
    "            final_label=1\n",
    "        else:\n",
    "            final_label=0\n",
    "        index_x=test_data_x.index(strobj)\n",
    "        if(final_label==test_data_y[index_x]):\n",
    "            correct+=1\n",
    "\n",
    "    accuracy=(correct/len(test_data_x))*100\n",
    "    return accuracy   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.0\n"
     ]
    }
   ],
   "source": [
    "acc_knn=knn_model(train_dis_x,train_dis_y,test_dis_x,test_dis_y)\n",
    "print(acc_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_arr=[]\n",
    "i=-1\n",
    "for data in x:\n",
    "    i=i+1\n",
    "    dist=len(data)/(len(ham_wd_set)+len(spam_wd_set))\n",
    "    obj={'x':data,'y':y[i],'dist':dist,'group':-1}\n",
    "    new_arr.append(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'x': 'go jurong point crazy available bugis n great world la e buffet cine got amore wat', 'y': 0, 'dist': 0.0004298640161880498, 'group': -1}, {'x': 'free entry 2 wkly comp win fa cup final tkts 21st may 2005 text fa 87121 receive entry questionstd txt ratetcs apply 08452810075over18s', 'y': 1, 'dist': 0.0007077029534803259, 'group': -1}]\n"
     ]
    }
   ],
   "source": [
    "#k-means , here k=2 becaues wants to divide into 2 groups spam and ham\n",
    "centers=[]\n",
    "centers.append(new_arr[0])\n",
    "centers.append(new_arr[2])\n",
    "c1_wd_set=set(word_tokenize(centers[0]['x']))\n",
    "c2_wd_set=set(word_tokenize(centers[1]['x']))\n",
    "print(centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "index=-1\n",
    "for data in new_arr:\n",
    "        index+=1\n",
    "        small=100#randomly 100\n",
    "\n",
    "        x_wd_set=set(word_tokenize(data['x']))\n",
    "   \n",
    "        intersec1 = x_wd_set.intersection(c1_wd_set)\n",
    "        union1 = x_wd_set.union(c1_wd_set)\n",
    "        \n",
    "        intersec2 = x_wd_set.intersection(c2_wd_set)\n",
    "        union2 = x_wd_set.union(c2_wd_set)\n",
    "        \n",
    "        dist1=len(intersec1)/len(union1)\n",
    "        dist2=len(intersec2)/len(union2)\n",
    "        \n",
    "        if(dist1>dist2):\n",
    "            new_arr[index]['group']=centers[0]['y']\n",
    "        else:\n",
    "            new_arr[index]['group']=centers[1]['y']\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.008717474600764762, 0.0071716864685213155]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "#center value cal\n",
    "a=pd.DataFrame(new_arr)\n",
    "groupby = a.groupby('group', axis=0)\n",
    "mean_dis=[]\n",
    "for index,itr in groupby.mean().iterrows():\n",
    "    \n",
    "    if(math.isclose(itr['dist'], centers[0]['dist'], rel_tol=1e-5)):\n",
    "        print(\"same\")\n",
    "    elif(math.isclose(itr['dist'], centers[1]['dist'], rel_tol=1e-5)):\n",
    "        print(\"same\")\n",
    "    else:\n",
    "        mean_dis.append(itr['dist'])\n",
    "print(mean_dis)\n",
    "for data in new_arr:\n",
    "    if(math.isclose(data['dist'], mean_dis[0], rel_tol=1e-5)):\n",
    "        centers[0]=data\n",
    "    if(math.isclose(data['dist'], mean_dis[1], rel_tol=1e-5)):\n",
    "        centers[1]=data\n",
    "centers\n",
    "c1_wd_set=set(word_tokenize(centers[0]['x']))\n",
    "c2_wd_set=set(word_tokenize(centers[1]['x']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "index=-1\n",
    "for data in new_arr:\n",
    "        index+=1\n",
    "        small=100#randomly 100\n",
    "\n",
    "        x_wd_set=set(word_tokenize(data['x']))\n",
    "   \n",
    "        intersec1 = x_wd_set.intersection(c1_wd_set)\n",
    "        union1 = x_wd_set.union(c1_wd_set)\n",
    "        \n",
    "        intersec2 = x_wd_set.intersection(c2_wd_set)\n",
    "        union2 = x_wd_set.union(c2_wd_set)\n",
    "        \n",
    "        dist1=len(intersec1)/len(union1)\n",
    "        dist2=len(intersec2)/len(union2)\n",
    "        \n",
    "        if(dist1>dist2):\n",
    "            new_arr[index]['group']=centers[0]['y']\n",
    "        else:\n",
    "            new_arr[index]['group']=centers[1]['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.008717474600764762, 0.0071716864685213155]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "#center value cal\n",
    "a=pd.DataFrame(new_arr)\n",
    "groupby = a.groupby('group', axis=0)\n",
    "mean_dis=[]\n",
    "for index,itr in groupby.mean().iterrows():\n",
    "    \n",
    "    if(math.isclose(itr['dist'], centers[0]['dist'], rel_tol=1e-5)):\n",
    "        print(\"\")\n",
    "    elif(math.isclose(itr['dist'], centers[1]['dist'], rel_tol=1e-5)):\n",
    "        print(\"\")\n",
    "    else:\n",
    "        mean_dis.append(itr['dist'])\n",
    "print(mean_dis)\n",
    "for data in new_arr:\n",
    "    if(math.isclose(data['dist'], mean_dis[0], rel_tol=1e-5)):\n",
    "        centers[0]=data\n",
    "    if(math.isclose(data['dist'], mean_dis[1], rel_tol=1e-5)):\n",
    "        centers[1]=data\n",
    "centers\n",
    "c1_wd_set=set(word_tokenize(centers[0]['x']))\n",
    "c2_wd_set=set(word_tokenize(centers[1]['x']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.236717169632165\n"
     ]
    }
   ],
   "source": [
    "correct=0\n",
    "acc_kmeans=0\n",
    "for data in new_arr:\n",
    "    if(data['group']==data['y']):\n",
    "        correct+=1\n",
    "acc_kmeans=(correct*100)/len(new_arr)\n",
    "print(acc_kmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "langs = ['NB', 'K-NN', 'K-means']\n",
    "students = [acc_NB,acc_knn,acc_kmeans]\n",
    "ax.bar(langs,students)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using dev dataset and aplha 0  99.91745769706975\n"
     ]
    }
   ],
   "source": [
    "acc_NB=test_model(test_x,test_y,0)\n",
    "print(\"Accuracy using dev dataset and aplha 0 \",acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using dev dataset and aplha 1  99.91745769706975\n"
     ]
    }
   ],
   "source": [
    "acc_NB=test_model(test_x,test_y,1)\n",
    "print(\"Accuracy using dev dataset and aplha 1 \",acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using dev dataset and aplha 1  99.91745769706975\n"
     ]
    }
   ],
   "source": [
    "acc_NB=test_model(test_x,test_y,1/10)\n",
    "print(\"Accuracy using dev dataset and aplha 1 \",acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "congrats winner 1000 amount\n"
     ]
    }
   ],
   "source": [
    "data=\"Congrats!! You are winner of 1000 amount.\"\n",
    "data=re.sub(r'[^a-z A-Z 0-9]', '', data)\n",
    "data=data.lower()\n",
    "w_t=word_tokenize(data)\n",
    "fs = [w for w in w_t if not w in s_w]\n",
    "data=\" \".join(fs)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam_prob  congrats 2.1240035768220234e-05\n",
      "hamm  congrats 3.1617987262166865e-06\n",
      "spam_prob  winner 3.1579738360469243e-09\n",
      "hamm  winner 3.161798726216687e-05\n",
      "spam_prob  1000 1.3616321878246288e-12\n",
      "hamm  1000 9.16921630602839e-05\n",
      "spam_prob  amount 5.813144390883573e-16\n",
      "hamm  amount 0.0002174614901697921\n",
      "Final Spam prob  1.8832179849497723e-14\n",
      "Final ham prob  3.9042357499239606e-16\n"
     ]
    }
   ],
   "source": [
    "w_t=word_tokenize(data)\n",
    "spam_prob=1\n",
    "ham_prob=1\n",
    "final_lable=-20#random value initialized\n",
    "for w in w_t:\n",
    "    if(w not in spam_wd_set):\n",
    "        spam_prob=spam_prob*0/(spam_count+2*0)\n",
    "    else:\n",
    "        spam_prob=spam_prob*((spam_wd_set[w]+0)/spam_count+2*0)\n",
    "        print(\"spam_prob \",w,spam_prob)\n",
    "    if(w not in ham_wd_set):\n",
    "         ham_prob=ham_prob*0/(ham_count+2*0)\n",
    "    else:\n",
    "        ham_prob=ham_prob*((ham_wd_set[w]+0)/ham_count+2*0)\n",
    "        print(\"hamm \",w,ham_wd_set[w]/ham_count)\n",
    "    \n",
    "spam_prob=spam_prob*spam_class_prob\n",
    "ham_prob=ham_prob*ham_class_prob\n",
    "print(\"Final Spam prob \",spam_prob)\n",
    "print(\"Final ham prob \",ham_prob)\n",
    "if(spam_prob>=ham_prob):\n",
    "    final_lable=1\n",
    "else:\n",
    "    final_lable=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_lable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to improve performance use email column of data\n",
    "data1 = pd.read_excel('spamham/SPAM text message 20170820 - Data1.xlsx')\n",
    "\n",
    "new_data=[]\n",
    "\n",
    "for key,row1 in data1.iterrows():\n",
    "    count=0\n",
    "    val=0\n",
    "    reply=0\n",
    "    stringmsg=re.sub(r'[^a-z A-Z 0-9]', '', str(row1['Message']))\n",
    "    stringmsg=stringmsg.lower()\n",
    "    stringemail=row1['Email']\n",
    "    if(row1['Category']=='spam'):\n",
    "        count+=1\n",
    "        val=1\n",
    "        if(count<4):\n",
    "            reply=1\n",
    "        else:\n",
    "            reply=0\n",
    "    else:\n",
    "        reply=1\n",
    "    obj={'strmsg':stringmsg,'stremail':stringemail,'category':val,'reply':reply}\n",
    "    new_data.append(obj)\n",
    "\n",
    "s_w = set(stopwords.words('english'))\n",
    "i=0\n",
    "for obj in new_data:\n",
    "    w_t=word_tokenize(obj['strmsg'])\n",
    "    fs = [w for w in w_t if not w in s_w]\n",
    "    strobj1=\" \".join(fs)\n",
    "    obj['strmsg']=strobj1\n",
    "    i=i+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#all words in spam without repeatation\n",
    "spam_wd_set1={}\n",
    "ham_wd_set1={}\n",
    "spam_domain_set1={}\n",
    "ham_domain_set1={}\n",
    "spam_count1=0\n",
    "ham_count1=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test dev ratio 80 20\n",
    "full_len=len(new_data)\n",
    "len_train=int(len(new_data)*0.8)\n",
    "\n",
    "train_data_new=new_data[0:len_train]\n",
    "test_data_new=new_data[len_train:full_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nb_classifier_improved(data):\n",
    "    global spam_wd_set1,ham_wd_set1,spam_domain_set1,ham_domain_set1\n",
    "    for strobj in data:\n",
    "        if(strobj['stremail']!=None and strobj['category']==1):\n",
    "            email=strobj['stremail']\n",
    "            if(type(email)==str):\n",
    "                dom=email[email.index('@') + 1 :email.index('.')]\n",
    "                if(dom not in spam_domain_set1):\n",
    "                    spam_domain_set1[dom]=1\n",
    "                else:\n",
    "                    countdom=spam_domain_set1[dom]\n",
    "                    spam_domain_set1[dom]=countdom+1\n",
    "        elif(strobj['stremail']!=None and strobj['category']==0):\n",
    "            email=strobj['stremail']\n",
    "            if(type(email)==str):        \n",
    "                dom=email[email.index('@') + 1 :email.index('.')]\n",
    "                if(dom not in ham_domain_set1):\n",
    "                    ham_domain_set1[dom]=1\n",
    "                else:\n",
    "                    countdom=ham_domain_set1[dom]\n",
    "                    ham_domain_set1[dom]=countdom+1\n",
    "            \n",
    "        w_t=word_tokenize(strobj['strmsg'])\n",
    "        w_t_set=set(w_t)\n",
    "        for w in w_t:\n",
    "            if strobj['category']==1:\n",
    "                if w not in spam_wd_set1:\n",
    "                    spam_wd_set1[w]=1\n",
    "                else:\n",
    "                    count=spam_wd_set1[w]\n",
    "                    spam_wd_set1[w]=count+1\n",
    "            else:\n",
    "                if w not in ham_wd_set1:\n",
    "                    ham_wd_set1[w]=1\n",
    "                else:\n",
    "                    count=ham_wd_set1[w]\n",
    "                    ham_wd_set1[w]=count+1                           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'strmsg': 'go jurong point crazy available bugis n great world la e buffet cine got amore wat',\n",
       " 'stremail': 'abc@test.com',\n",
       " 'category': 0,\n",
       " 'reply': 1}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classifier_improved(train_data_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in train_data_new:\n",
    "    if(d['category']==1):\n",
    "        spam_count1+=1\n",
    "    else:\n",
    "        ham_count1+=1\n",
    "        \n",
    "spam_class_prob1=spam_count1/len(train_data_new)\n",
    "ham_class_prob1=ham_count1/len(train_data_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model1(data_new,alpha):\n",
    "    \n",
    "    i=0\n",
    "    correct_count=0\n",
    "    accuracy=0\n",
    "    for data in data_new:\n",
    "        dom_prob_spam=1\n",
    "        dom_prob_ham=1\n",
    "        if(data['stremail']!=None and data['category']==1):\n",
    "            email=data['stremail']\n",
    "            if(type(email)==str):\n",
    "                dom=email[email.index('@') + 1 :email.index('.')]\n",
    "                if(dom in spam_domain_set1):\n",
    "                    count=spam_domain_set1[dom]\n",
    "                    dom_prob_spam=count/spam_count1\n",
    "                if(dom in ham_domain_set1):\n",
    "                    count=ham_domain_set1[dom]\n",
    "                    dom_prob_ham=count/ham_count1                \n",
    "        w_t=word_tokenize(data['strmsg'])\n",
    "        spam_prob=1\n",
    "        ham_prob=1\n",
    "        final_lable=-20#random value initialized\n",
    "        for w in w_t:\n",
    "            if(w not in spam_wd_set1):\n",
    "                spam_prob=spam_prob*(alpha/(spam_count1+2*alpha))*dom_prob_spam\n",
    "                #print(\"spam \",spam_prob)\n",
    "            else:\n",
    "                spam_prob=spam_prob*((spam_wd_set1[w]+alpha)/(spam_count1+2*alpha))*dom_prob_spam\n",
    "            if(w not in ham_wd_set1):\n",
    "                ham_prob=ham_prob*(alpha/(ham_count1+2*alpha))*dom_prob_ham\n",
    "                #print(\"ham \",ham_prob)\n",
    "            else:\n",
    "                ham_prob=ham_prob*((ham_wd_set1[w]+alpha)/(ham_count1+2*alpha))*dom_prob_ham\n",
    "       \n",
    "        \n",
    "        spam_prob=spam_prob*spam_class_prob1\n",
    "        ham_prob=ham_prob*ham_class_prob1\n",
    "        if(spam_prob>=ham_prob):\n",
    "            final_lable=1\n",
    "        else:\n",
    "            final_lable=0\n",
    "        if(data['category']==final_lable):\n",
    "            correct_count=correct_count+1\n",
    "        i=i+1\n",
    "\n",
    "    accuracy=(correct_count/len(data_new))*100\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60.17937219730942"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model1(test_data_new,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model2(data_new,alpha):\n",
    "    \n",
    "    i=0\n",
    "    correct_count=0\n",
    "    accuracy=0\n",
    "    for data in data_new:\n",
    "        dom_prob_spam=1\n",
    "        dom_prob_ham=1\n",
    "        if(data['stremail']!=None and data['category']==1):\n",
    "            email=data['stremail']\n",
    "            if(type(email)==str):\n",
    "                dom=email[email.index('@') + 1 :email.index('.')]\n",
    "                if(dom in spam_domain_set1):\n",
    "                    count=spam_domain_set1[dom]\n",
    "                    dom_prob_spam=count/spam_count1\n",
    "                if(dom in ham_domain_set1):\n",
    "                    count=ham_domain_set1[dom]\n",
    "                    dom_prob_ham=count/ham_count1                \n",
    "        w_t=word_tokenize(data['strmsg'])\n",
    "        spam_prob=1\n",
    "        ham_prob=1\n",
    "        final_lable=-20#random value initialized\n",
    "        for w in w_t:\n",
    "            if(w not in spam_wd_set1):\n",
    "                spam_prob=spam_prob*(alpha/(spam_count1+2*alpha))*dom_prob_spam\n",
    "                #print(\"spam \",spam_prob)\n",
    "            else:\n",
    "                spam_prob=spam_prob*((spam_wd_set1[w]+alpha)/(spam_count1+2*alpha))*dom_prob_spam\n",
    "            if(w not in ham_wd_set1):\n",
    "                ham_prob=ham_prob*(alpha/(ham_count1+2*alpha))*dom_prob_ham\n",
    "                #print(\"ham \",ham_prob)\n",
    "            else:\n",
    "                ham_prob=ham_prob*((ham_wd_set1[w]+alpha)/(ham_count1+2*alpha))*dom_prob_ham\n",
    "       \n",
    "        \n",
    "        spam_prob=spam_prob*spam_class_prob1\n",
    "        ham_prob=ham_prob*ham_class_prob1\n",
    "        if(spam_prob>ham_prob and data['reply']==0):\n",
    "            final_lable=1\n",
    "        else:\n",
    "            final_lable=0\n",
    "        if(data['category']==final_lable):\n",
    "            correct_count=correct_count+1\n",
    "        i=i+1\n",
    "\n",
    "    accuracy=(correct_count/len(data_new))*100\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60.17937219730942"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model1(test_data_new,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
